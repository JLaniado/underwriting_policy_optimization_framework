üß≠ Credit Policy Optimization Framework

Private Repository ‚Äî Internal Use Only

This repository contains a proposed slution for Nelo's Credit Risk business case. Goal is to show the ability to identify, test, and monitor rules that reduce First Payment Default (FPD) while maintaining healthy approval rates.

The framework combines statistical rigor, interpretability, and operational scalability to support data-driven credit-policy adjustments. It was built as a reusable, parameter-free system that can be applied across portfolios, seasons, and product types.

‚∏ª

üìå Purpose

The goal of this project is to enable the systematic discovery and evaluation of credit rules that balance growth and risk.
Rather than running ad-hoc analyses, the framework provides a consistent, repeatable process to:
	‚Ä¢	Detect pockets of elevated default or fraud risk.
	‚Ä¢	Quantify the trade-off between risk reduction and applicant retention.
	‚Ä¢	Translate model outputs into interpretable business rules ready for testing or deployment.

‚∏ª

üîç Summary of Approach
	1.	Data preparation
	‚Ä¢	Cleans and validates raw application-level data.
	‚Ä¢	Flags missing values (presence or absence as information).
	‚Ä¢	Encodes categorical variables via one-hot or target encoding.
	‚Ä¢	Creates standardized risk bands from the underwriting score to enable peer-group analysis.
	2.	Feature exploration
	‚Ä¢	Computes variable correlation to FPD overall and per risk band.
	‚Ä¢	Identifies high-signal numerical and categorical variables.
	3.	Rule discovery
	‚Ä¢	Trains a shallow Decision Tree Classifier to segment pre-application populations.
	‚Ä¢	Translates each leaf into a plain-language rule (e.g., acquisition_uw_score <= 0.597 & apps_installed_count < 360).
	‚Ä¢	Ranks rules by efficiency (FPD reduction per % of population removed).
	4.	Impact assessment
	‚Ä¢	Applies rules individually and cumulatively.
	‚Ä¢	Measures changes in:
	‚Ä¢	Overall and per-band FPD
	‚Ä¢	Approval rate (kept %)
	‚Ä¢	Good vs. bad volume composition
	‚Ä¢	Produces ready-to-use metrics and visual reports.
	5.	Visualization suite
	‚Ä¢	Trade-off curves ‚Äî FPD vs. applicants removed.
	‚Ä¢	Single-rule impact ‚Äî marginal and cumulative effects.
	‚Ä¢	Waterfall charts ‚Äî absolute and relative volume changes.
	‚Ä¢	Purity analysis ‚Äî quality of removed population.
	‚Ä¢	FPD by band ‚Äî distributional stability check.

‚∏ª

üìä Example Outcome

Metric	Baseline	After Rules	Œî
Overall FPD	25.0 %	22.9 %	‚Üì 2.1 p.p.
Applicants Kept	100 %	93.0 %	‚Üì 7 p.p.
Bad Accounts	45,615	38,804	-6,811
Good Accounts	136,847	130,913	-5,934

The framework‚Äôs six recommended rules target the lowest-score bands and segments showing high utilization or weak carrier profiles, achieving measurable improvement with minimal volume loss.

‚∏ª

üß† Design Philosophy

This project was built as a sandbox with production intent ‚Äî balancing exploratory flexibility with engineering discipline:
	‚Ä¢	Fully automated notebook: click-to-run with no hardcoded variables.
	‚Ä¢	Parameterization: adaptable to any dataset following the same schema.
	‚Ä¢	Code readability: each function self-contained for review or audit.
	‚Ä¢	Infrastructure-ready: designed for future deployment in batch or API format.

The approach reflects a long-term view of risk analytics ‚Äî favoring transparency, reusability, and governance readiness over one-off modeling.

‚∏ª

‚öôÔ∏è Repository Structure

/fpd_rule_mining.ipynb        ‚Üí Main analysis notebook  
/data/                         ‚Üí Raw input and interim CSVs  
/outputs/                      ‚Üí Leaf summaries, stage metrics, and charts  
clean_rules.md                 ‚Üí Final rule set (ready for A/B testing)  
metrics.json                   ‚Üí Global KPIs and performance metrics  


‚∏ª

üß© How to Reuse
	1.	Update the file path in the configuration cell (FILEPATH = ...).
	2.	Run all cells sequentially in Jupyter.
	3.	Review generated outputs:
	‚Ä¢	leaf_summary.csv for rule details.
	‚Ä¢	single_rule_impact.csv for marginal results.
	‚Ä¢	cumulative_stages.csv for progressive impact.
	‚Ä¢	Exported visuals under /outputs/.
	4.	Use clean_rules.md as the baseline for policy simulation or A/B testing.

‚∏ª

üîí Access and Governance
	‚Ä¢	Classification: Confidential
  
‚∏ª

üß≠ Next Steps
	‚Ä¢	Extend framework to expected-loss (ECL) and profitability analysis.
	‚Ä¢	Add temporal validation and drift detection.
	‚Ä¢	Integrate a lightweight dashboard for ongoing monitoring.
	‚Ä¢	Link directly to the underwriting API for simulation of rule deployment.

‚∏ª

Author: Jaime Laniado Cohen
Owner: Jaime Laniado Cohen
Repository: Private

‚∏ª
